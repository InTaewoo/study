## 다루는내용
- 도커를 사용한 컨테이너 이미지 생성, 실행, 공유
- 로컬에서 단일 노드 쿠버네티스 클러스터 실행
- 구글 쿠버네티스 엔진에서 쿠버네티스 클러스터 설치
- kubectl CLI 클라이언트 설정과 사용
- 쿠버네티스에서 애플리케이션의 배포와 수평 스케일링

## 도커 설치와 Hello World 컨테이너 실행하기

![image](https://user-images.githubusercontent.com/81672260/147534314-7d940042-abf1-4fbd-a330-7a480f6e142f.png)

- busybox는 echo, ls, gzip 등과 같은 표준 UNIX 명령줄 도구들을 합쳐 놓은 단일 실행파일.
- busybox 이미지를 실행하기 위해 어떤 것도 다운로드하거나 설치할 필요가 없고 docker run 커맨드를 사용해 다운로드한다.

![image](https://user-images.githubusercontent.com/81672260/147534780-41cd4892-ed9d-42ab-a44b-b2e65fb7422a.png)
1. docker run busybox echo "Hello world"를 입력한다
2. 도커는 로컬 머신에 busybox 이미지가 저장돼 있는지 확인한다.
3. 로컬에 이미지가 없으면 도커는 레지스트리로부터 이미지를 풀(pull)한다.
4. 도커가 격리된 컨테이너에서 echo "Hello world"를 실행한다.

## 간단한 node.js 애플리케이션 생성하기

![image](https://user-images.githubusercontent.com/81672260/147535777-1811eef3-5d20-4883-a14c-918efcd12b38.png)


간단한 Node.js 웹 애플리케이션을 만들고 컨테이너 이미지로 패키징한다. 이 코드가 하는일은 `포트 8080`으로 HTTP서버를 시작하고, 
서버는 모든 요청에 대해 상태 코드 200 OK 와 "You ve hit <hostname>"의 텍스트를 HTTP 응답으로 한다.

  
## 이미지를 위한 Dockerfile 생성
![image](https://user-images.githubusercontent.com/81672260/147536970-f95a9c6e-98a1-427c-8d3c-f172a2a887b0.png)

- FROM 줄은 시작점(이미지 생성의 기반이 되는 기본 이미지)으로 컨테이너 이미지를 정의. 이 경우 node 컨테이너 이미지의 태그 7 을 사용.
- 두번째 줄은 로컬디렉터리의 app.js파일을 이미지의 루트 디렉터리에 추가.
- 세번째 줄에서는 이미지를 실했을 때 수행돼야 할 명령어를 정의(node app.js)
  
  
  ### 실행중인 컨테이너 조회
  
  ```
  docker ps
  ```
  ![image](https://user-images.githubusercontent.com/81672260/147617042-53074288-9a48-4cd1-8bfb-c4720eed9c63.png)
  

  
## 컨테이너 이미지 생성
  
```
docker build -t kubia .
```
이미지를 빌드하려면 다음 도커 명령어를 실행한다.
  
  ![image](https://user-images.githubusercontent.com/81672260/147544293-df6a1831-b137-4d29-bb0c-9146d54ca14b.png)
  
  ![image](https://user-images.githubusercontent.com/81672260/147544523-130add45-7db6-4316-88de-6c4b38e056da.png)
  
  - 도커 클라이언트와 데몬은 같은 머신에 있을 필요가 없다.

## 컨테이너 이미지 실행
  ```
  docker run --name kubia-container -p 8080:8000 -d kubia
  ```
  - 이 명령어는 도커가 kubia 이미지에서 `kubia-container` 라는 이름의 새로운 컨테이너를 실행하도록 한다.
  - `-d ` = 컨테이너는 콘솔에서 분리돼 백그라운드에서 실행됨을 의미.
  - 로컬 머신의 8080포트가 컨테이너 내부의 8080포트와 매핑되므로 http://localhost:8080 으로 접근가능.

### 실행 중인 컨테이너 조회
  ```
  docker ps
  ```
  ![image](https://user-images.githubusercontent.com/81672260/147617089-9b8633f3-9121-4b7d-b2f4-bc19a8246771.png)
  
  모든 컨테이너 리스트 확인
  
  더 자세한 정보를 얻고 싶으면
  ```
  docker inspect kubia-container
  ```
  - 도커 컨테이너의 상세 정보를 JSON 형식으로 출력함
  
  ## 실행 중인 컨테이너 내부 탐색하기
  
  - 실행 중인 컨테이너의 기본 이미지인 Node.js는 bash 셸을 포함하고 있으므로 다음과 같이 컨테이너 내부에서 셸을 실행할 수 있다.
  
  ```
  docker exec -it kubia-container bash
  ```
  ![image](https://user-images.githubusercontent.com/81672260/147617204-8738424c-3e01-46b2-881d-cb08d7d80a0c.png)

## 내부에서 컨테이너 탐색
  ```
  ps aux
  ```
  ![image](https://user-images.githubusercontent.com/81672260/147617458-a37d844c-ba98-48a4-9071-b89a76013b06.png)

  ## 호스트 운영체제에서 실행중인 컨테이너에서 실행되는 프로세서 이해하기
  ```
  ps aux | grep app.js
  ```
  
  ## 격리된 컨테이너 파일시스템
  
  ```
  ls/
  ```
  ![image](https://user-images.githubusercontent.com/81672260/147617910-00b1d6e8-4d1a-4d45-977e-b218846b8828.png)
- 격리된 프로세스를 가진 것과 마찬가지로 각 컨테이너는 격리된 파일시스템을 갖고 있다.
  
  ## 컨테이너 중지와 삭제
  
 ```
  docker stop kubia-container
  ```
 이 명령어는 컨테이너에 실행중인 메인 프로세스를 중지시킴 
 `docker ps` 를 사용하면 실행 중인 컨테이너가 사라지지만
  `docker ps -a`를 입력하면 컨테이너 그 자체는 여전치 존재함을 확인할 수 있다. 따라서 rm명령을 수행해야 한다
  
  ```
  docker rm kubia-container
  ```
  
  ## 이미지 레지스트리에서 이미지 푸쉬
  
 지금까지 빌드한 이미지는 로컬 컴퓨터에서만 사용이 가능했다. 다른 컴퓨터에서도 사용하려면 외부 이미지 저장소에 푸쉬를 해야한다.
  이미지를 푸쉬하기전 도커 허브의 규칙에 따라 이미지 태그를 다시 지정해야 한다.
  
  ```
  docker tag kubia oilehot0910/kubia
  ```
  ![image](https://user-images.githubusercontent.com/81672260/147618604-98a7a093-4c9f-46c4-bc57-24090e40ac80.png)

  ## 도커 허브에 푸시하기
  - 도커 허브에 푸시하기 전에 `docker login`명령을 이용해 로그인 해야한다.
  
  ```
  docker push oilehot0910/kubia
  ```
  ![image](https://user-images.githubusercontent.com/81672260/147618656-88439c47-fc20-4e61-a9f1-bb1249f43c5d.png)

  
 ## 다른 머신에서 이미지 실행하기
  - 도커 허브에 이미지 푸시가 완료되면 모든 사람이 이미지를 사용할 수 있다.
  
  ```
  docker run -p 8080:8080 -d oilehot0910/kubia
  ```
  
  ![image](https://user-images.githubusercontent.com/81672260/147618746-d53acaa8-4916-4a9f-8a50-dc62ae53ea80.png)

  
  ![image](https://user-images.githubusercontent.com/81672260/147618785-6547be71-5bc6-4a73-9f51-82d48250e1cc.png)
  
  도커 허브 확인
  
  ## Minikube를 활용한 단일 노드 쿠버네티스 클러스터 실행하기
  - 쿠버네티스를 가장 간단하고 빠르게 접근하는 방법은 Minikube를 사용하는 것이다.
  - Minikube는 로컬에서 쿠버네티스를 테스트하고 애플리케이션을 개발하는 목적으로 단일 노드 클러스터를 설치하는 도구다.
  
  ### [Minikube설치](https://minikube.sigs.k8s.io/docs/start/)
  
  ```
  curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64
sudo install minikube-linux-amd64 /usr/local/bin/minikube
  ```
  
  * 설치할 때 CPU오류시 VirtualBox CPU수를 2개 이상으로 할당해 주어야 한다.
  
  ### Minikube로 쿠버네티스 클러스터 시작하기
  ```
  minikube start시 오류
  minikube start --driver=virtualbox
  ```
  
  `Unable to start VM: create: precreate: This computer doesn't have VT-X/AMD-v enabled. Enabling it in the BIOS is mandatory` 오류 발생시
  cmd -> VirtualBox 설치 폴더 -> VBoxManage.exe modifyvm "ubuntu" --nested-hw-virt on (강제로 네스티드 VT-x/AMD-V사용)
  
  ### The connection to the server localhost:8080 was refused - did you specify the right host or port? 발생 오류
  
  ```
 mkdir -p $HOME/.kube
 sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
 sudo chown $(id -u):$(id -g) $HOME/.kube/config
  ```
  
  
## minikube 가상머신 시작하기
  쿠버네티스 설치 후 클러스터 정보가 정상 작동하는지 확인.
  
  ```
  kubectl cluster-info
  ```
  
  ## 구글 클러스터 엔진을 활용한 관리형 쿠버네티스 클러스터 사용하기
  - 완전한 다중 노드 쿠버네티스 클러스터를 살펴보려면 관리형 구글 쿠버네티스 엔진 즉 ,GKE 클러스터를 사용할 수 있다.
  
  ### 노드 3개를 가진 쿠버네티스 클러스터 생성
  ```
  gcloud container clusters create kubia --num-nodes 3
  ```
  워커 노드 3개를 가진 쿠버네티스 클러스터 생성. 노드 3개를 사용하며 다중 노드를 활용하는 기능을 제대로 시연해 볼 수 있다.
  
  ![image](https://user-images.githubusercontent.com/81672260/147634622-5dd02395-fe0f-44e4-a369-9f9eca583488.png)
  
  ## 클러스터 개념 이해하기
  ![image](https://user-images.githubusercontent.com/81672260/147635148-d93e3e1e-2e02-4383-bad9-aab024f4f318.png)

 - 각 노드는 docker, kubelet, kube-proxy를 실행한다.
  
  ## 클러스터 노드를 조회해 클러스터 동작 상태 확인하기
  ```
  kubectl get nodes
  ```
  ![image](https://user-images.githubusercontent.com/81672260/147635386-ce63d7ef-1d20-4e65-b398-044c7b9c001d.png)

  - 3개의 워커노드가 생성된 것을 확인할 수 있다.
  
## 워커 노드 세부 정보 가져오기
  ```
  kubectl describe node gke-kubia-default-pool-ac16616d-1gs5
```
 
  - describe 명령의 출력 결과는 상당히 읽기 어려움. CPU, 매모리, 시스템 정보, 노드에 실행 중인 컨테이너 등을 포함한 노드 상태를 보여줌
  - `kubectl describe node`라고 수행하면 모든 노드의 상세 정보가 출력.
  
## 쿠버네티스 첫 번째 애플리케이션 실행하기
  - 보통 배포하고자 하는 모든 구성 요소를 기술한  JSON이나 YAML을 준비해야 하지만 따로 아직 언급을 하지 않았기 때문에 간단한 명령어 한 줄로 실행
  
  ### Node.js 애플리케이션 구동하기
  ```
  kubectl run kubia --image=oilehot0910/kubia --port=8080
  ```
  - --image=oilehot0910/kubia 부분은 실행하고자 하는 컨테이너 이미지를 명시하는 것이고 -port=8080 옵션은 쿠버네티스 애플리케이션이 8080 포트를 수신 대기해야 한다는 것이다.
  
  ## 백그라운드 에서 일어난 동작 이해하기
  - 컨테이너 이미지를 가져오기 위해 수행하는 모든 단계
  ![image](https://user-images.githubusercontent.com/81672260/147713541-3ef0b423-35e5-4908-af62-bc9cec51dde4.png)

  1. `docker push oilehot0910/kubia`
  2. oilehot0910/kubia 이미지를 도커 허브에 푸시함.
  3. `kubectl run kubia --image=oilehot0910/kubia --port=8080`
  4. kubectl은 REST 호출을 한다.
  5. 파드가 생성되고 워커 노드에 스케줄링 된다.
  6. Kublet은 통지를 받는다.
  7. kubelet은 도커에 이미지를 실행하라고 지시한다.
  8. 도커는 이미지를 pull하고 oilehot0910/kubia를 실행한다
  
  
  
  
- 스케줄링(Scheduling) : 파드가 특정 노드에 할당됨을 의미. 파드는 즉시 실행된다. 용어의 의미처럼 미래의 특정 시간에 실행됨을 의미하는 것이 아니다.
  
  ## 웹 애플리케이션에 접근하기
  
  실행중인 파드에 어떻게 접근할 수 있을까? 각 파드는 IP주소를 가지고 있지만 이 주소는 클러스터 내부에 있으며 외부에서 접근이 불가능하다.
  외부에서 접근을 가능하게 하려면 `서비스 오브젝트`를 통해 노출해여 한다.
  
  ## 서비스 오브젝트 생성하기
  
 - 서비스를 생성하기 위해 쿠버네티스에게 앞서 생성한 레플리케이션컨트롤러를 노출하도록 명령.
  
  ```
  kubectl create -f 'kubia.yaml'
  kubectl get services
  ```
  
  ![image](https://user-images.githubusercontent.com/81672260/147714703-2d6a65dd-4564-4876-b21a-14e0bdbc1c64.png)

  앞서 생성한 레플리케이션 컨트롤러를 노출하도록 명령
  
  ```
  kubectl expose rc kubia --type=LoadBalancer --name kubia-http service "kubia-http" exposed
  ```
  
  ### 서비스 조회하기
  ```
  kubect get servivces
  ```
  
  
![image](https://user-images.githubusercontent.com/81672260/147714726-28dda9b5-cdd1-43bb-97e1-e842e5ab6774.png)
  
 ## EXTERNAL-IP가 할당된 후 서비스 접근하기
  
  ```
  curl 104.197.140.49
  ```
  
  ## 레플리케이션컨트롤러(ReplicationController)의 역할 이해
  - 보통 RC(RepliecationController)는 파드를 복제하고 항상 실행 상태로 만든다.
  - 여기 에서는 파드의 레플리카를 지정하지 않았기 때문에 rc는 파드를 하나만 생성했다.
  - 어떤 이유로 파드가 사라진다면 rc는 사라진 파드를 대체하기 위해 새로운 파드를 생성.
  
## 서비스가 필요한 이유
  - 파드는 일시적이기 때문에 언제든지 사라질 수 있다.
  - 이러한 상황이 발생하면 앞서 설명한 대로 사라진 파드는 rc에 의해 생성된 파드로 대체된다.
  - 새로운 파드는 다른 IP 주소를 할당받고, 여러개의 파드를 단일 IP와 포트의 쌍으로 노출시키는 문제를 해결하기 위해 서비스가 필요하다.
  - 서비스가 생상되면 정적 IP를 할당받고 서비스가 존속되는 동안 변경되지 않음
  
  ## 애플리케이션 수평 확장
  
  ```
  kubectl get replicationcontrollers
  kubect get rc
  ```
  ![image](https://user-images.githubusercontent.com/81672260/147716718-056084dd-1685-4ffa-b314-233d7e76a68c.png)
  
  현재는 복제의수가 1개
  
## 레플리카 수 늘이기
  
  ```
  kubectl scale rc kubia --replicas=3
  ```
  ![image](https://user-images.githubusercontent.com/81672260/147716774-b0773970-a9ae-4789-9e14-a1a81639561e.png)

  ## 서비스 호출 시 모든 파드가 요청을 받는지 확인
  
  ![image](https://user-images.githubusercontent.com/81672260/147721236-1a24c146-fe0d-4877-b55a-d93b2d8d96bf.png)
  kubia-8mn9n 파드
  
  ![image](https://user-images.githubusercontent.com/81672260/147721243-6fecce29-5183-4286-9678-721bae14fe22.png)
  kubia-x7tmf 파드
  
  ![image](https://user-images.githubusercontent.com/81672260/147721256-e248364a-1fdb-432d-add6-2121c49e6559.png)

- 요청이 무작위로 다른 파드를 호출함 
- 파드가 하나만 있으면 이 파드 하나에 정적 주소를 제공하기 때문에 서비스는 항상 `동일한 주소`를 가진다.
  
  ## 시스템의 새로운 상태 시각화
  ![image](https://user-images.githubusercontent.com/81672260/147721574-19a4cdef-9652-44e0-a4df-1c4c9cbca28d.png)

  - 동일한 rc에 의해 관리되는 3개의 파드 인스턴스가 단일 IP와 포트로 노출됐다.
  
  ## 애플리케이션이 실행 중인 노드 검사하기
  
  ### 파드를 조회할 때 파드 IP와 실행 중인 노드 표시하기
  ```
  kubectl get pods -o wide
  ```
  ![image](https://user-images.githubusercontent.com/81672260/147721709-be80dbba-eef5-4a9a-b8b6-ba542d3312b6.png)
  
  - IP, NODE 등 더 많은 열을 보여줄 수 있다.

### kubectl describe로 파드 세부 정보 살펴보기
  
  ```
  kubectl describe pod kubia-2ldnw
  ```
  
  
